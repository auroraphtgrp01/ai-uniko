from src.utils.amount_parser import AmountParser
from src.models.wallet import Wallet
import re
from typing import Dict, List
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))


class TextParser:
    def __init__(self):
        self.amount_parser = AmountParser()
        self.category_keywords = {
            "4287f00a-9f2c-4ec9-bfac-9310a5430b13": {  # ƒÇn u·ªëng
                "keywords": ["ƒÉn", "c∆°m", "b·ªØa", "tr∆∞a", "t·ªëi", "s√°ng", "ph·ªü", "b√∫n", "ch√°o", "ƒë·ªì ƒÉn", "c∆°m vƒÉn ph√≤ng", "qu√°n ƒÉn"],
                "name": "üç≤ ƒÇn u·ªëng",
                "type": "EXPENSE"
            },
            "0b8f45d7-53f3-4404-ace0-23935b502e32": {  # Gi·∫£i tr√≠
                "keywords": ["ƒÉn v·∫∑t", "nem chua", "tr√† s·ªØa", "cafe", "xem phim", "karaoke", "du l·ªãch", "gi·∫£i tr√≠", "game", "netflix", "spotify"],
                "name": "üé¨ Gi·∫£i tr√≠",
                "type": "EXPENSE"
            },
            "36f9961f-2be4-4c01-bdd5-26f1873fde89": {  # Mua s·∫Øm
                "keywords": ["mua", "qu·∫ßn √°o", "gi√†y", "t√∫i", "ƒë·ªì", "shopping", "th·ªùi trang", "ph·ª• ki·ªán"],
                "name": "üõçÔ∏è Mua s·∫Øm",
                "type": "EXPENSE"
            },
            "8835247e-28b7-4668-a2b6-2ddb29ba35f4": {  # XƒÉng xe
                "keywords": ["xƒÉng", "ƒë·ªï xƒÉng", "d·∫ßu", "nhi√™n li·ªáu"],
                "name": "‚õΩ XƒÉng xe",
                "type": "EXPENSE"
            },
            "1eead838-d02f-4d2e-b5b1-ba98f10eb9b6": {  # Ti·ªÅn ƒëi·ªán
                "keywords": ["ƒëi·ªán", "ti·ªÅn ƒëi·ªán", "h√≥a ƒë∆°n ƒëi·ªán", "ƒëi·ªán l·ª±c"],
                "name": "üí° Ti·ªÅn ƒëi·ªán",
                "type": "EXPENSE"
            },
            "4ad0cb83-54fb-4cbf-b7ee-4689b1128a60": {  # Thu√™ tr·ªç
                "keywords": ["thu√™", "tr·ªç", "nh√† tr·ªç", "ph√≤ng", "ti·ªÅn nh√†", "ti·ªÅn tr·ªç", "ti·ªÅn thu√™ nh√†"],
                "name": "üè† Thu√™ tr·ªç",
                "type": "EXPENSE"
            },
            "26fe0933-4ded-4674-99a7-8b0eb8950763": {  # ƒêi·ªán tho·∫°i, internet
                "keywords": ["ƒëi·ªán tho·∫°i", "internet", "wifi", "4g", "5g", "data", "c∆∞·ªõc"],
                "name": "üì± ƒêi·ªán tho·∫°i, internet",
                "type": "EXPENSE"
            },
            "a02de534-75ef-4198-86ea-ec3875dc16cb": {  # S·ª©c kh·ªèe
                "keywords": ["thu·ªëc", "b·ªánh vi·ªán", "kh√°m", "b√°c sƒ©", "y t·∫ø", "s·ª©c kh·ªèe", "b·∫£o hi·ªÉm"],
                "name": "üíä S·ª©c kh·ªèe",
                "type": "EXPENSE"
            },
            "960a249d-0c94-4f67-a814-348e77fa40e8": {  # Ti·ªÅn n∆∞·ªõc
                "keywords": ["n∆∞·ªõc", "ti·ªÅn n∆∞·ªõc", "h√≥a ƒë∆°n n∆∞·ªõc"],
                "name": "üö∞ Ti·ªÅn n∆∞·ªõc",
                "type": "EXPENSE"
            },
            "61ad994c-9b06-4abb-b26a-f3e138c1c68b": {  # Gi√°o d·ª•c
                "keywords": ["h·ªçc", "s√°ch", "kh√≥a h·ªçc", "h·ªçc ph√≠", "gi√°o d·ª•c", "ƒë√†o t·∫°o", "thi"],
                "name": "üìö Gi√°o d·ª•c",
                "type": "EXPENSE"
            },
            "0d39a602-78c4-43b9-b3a1-99349d4b849b": {  # T√¨nh y√™u
                "keywords": ["qu√†", "h·∫πn h√≤", "valentine", "sinh nh·∫≠t", "k·ª∑ ni·ªám", "ng∆∞·ªùi y√™u"],
                "name": "üíñ T√¨nh y√™u",
                "type": "EXPENSE"
            },
            "db2dedb1-1d5c-4c8a-83ba-62d77e3f334f": {  # ƒêi l·∫°i
                "keywords": ["taxi", "grab", "xe bus", "xe bu√Ωt", "t√†u", "v√©", "g·ª≠i xe", "ƒëi l·∫°i"],
                "name": "üöï ƒêi l·∫°i",
                "type": "EXPENSE"
            },
            # Thu nh·∫≠p
            "cc13076d-54d2-43d6-a924-2b69ca0e7642": {  # Ti·ªÅn th∆∞·ªüng
                "keywords": ["th∆∞·ªüng", "bonus", "th∆∞·ªüng tt", "th∆∞·ªüng d·ª± √°n"],
                "name": "üíµ Ti·ªÅn th∆∞·ªüng",
                "type": "INCOMING"
            },
            "739366b8-0f04-4de7-910a-8b72e163c785": {  # Ph·ª• c·∫•p c√¥ng vi·ªác
                "keywords": ["ph·ª• c·∫•p", "tr·ª£ c·∫•p", "ph·ª• c·∫•p ƒÉn tr∆∞a", "ph·ª• c·∫•p ƒëi l·∫°i"],
                "name": "üè¢ Ph·ª• c·∫•p c√¥ng vi·ªác",
                "type": "INCOMING"
            },
            "c0e527cc-0387-433e-ba0e-64b6a44f774a": {  # L∆∞∆°ng
                "keywords": ["l∆∞∆°ng", "salary", "ti·ªÅn l∆∞∆°ng", "l∆∞∆°ng th√°ng"],
                "name": "üíº L∆∞∆°ng",
                "type": "INCOMING"
            },
            "1bbb0811-8a9d-4d55-b4dc-7cd7432dfdf4": {  # Ph·ª• c·∫•p gia ƒë√¨nh
                "keywords": ["ti·ªÅn m·ª´ng", "l√¨ x√¨", "tr·ª£ c·∫•p", "ti·ªÅn gia ƒë√¨nh"],
                "name": "üë™ Ph·ª• c·∫•p gia ƒë√¨nh",
                "type": "INCOMING"
            },
            "6b31159b-333f-4942-9e61-06689304440c": {  # B√°n t√†i s·∫£n
                "keywords": ["b√°n", "thanh l√Ω", "b√°n ƒë·ªì", "b√°n xe"],
                "name": "üè† B√°n t√†i s·∫£n",
                "type": "INCOMING"
            },
            "14cd8426-26ca-4700-bb80-9bbeaa74f480": {  # L√†m th√™m
                "keywords": ["l√†m th√™m", "part time", "freelance", "ngo√†i gi·ªù"],
                "name": "‚è∞ L√†m th√™m",
                "type": "INCOMING"
            }
        }

    def parse_transactions(self, text: str, wallets: List[Dict]) -> List[Dict]:
        """Ph√¢n t√≠ch th√¥ng minh n giao d·ªãch t·ª´ vƒÉn b·∫£n"""
        text = text.lower().strip()
        results = []

        # T√°ch c√°c giao d·ªãch b·∫±ng t·ª´ kh√≥a li√™n k·∫øt
        transactions = re.split(
            r'\s*(?:r·ªìi|sau ƒë√≥|ti·∫øp theo|v√†|v·ªõi|c√πng v·ªõi|,)\s*', text)

        # X√°c ƒë·ªãnh v√≠ t·ª´ c√¢u g·ªëc
        wallet = None
        wallet_keywords = ['v√≠', 't·ª´', 'trong', 't√†i kho·∫£n']
        for keyword in wallet_keywords:
            if keyword in text:
                wallet_str = text[text.find(keyword):]
                wallet = Wallet.find_wallet_by_text(wallets, wallet_str)
                break

        # N·∫øu kh√¥ng t√¨m th·∫•y v√≠ c·ª• th·ªÉ, d√πng v√≠ m·∫∑c ƒë·ªãnh
        if not wallet and wallets:
            wallet = next(
                (w for w in wallets if w["type"] == "WALLET" and "ti·ªÅn m·∫∑t" in w["name"].lower()), wallets[0])

        # ƒêi·ªÅu ch·ªânh pattern ƒë·ªÉ b·∫Øt: [h√†nh ƒë·ªông/ƒë·ªông t·ª´] [h·∫øt/m·∫•t] [s·ªë ti·ªÅn + ƒë∆°n v·ªã]
        amount_pattern = r'(.*?)(?:\s+(?:h·∫øt|m·∫•t|t·ªën|chi)\s+)?(\d+|m·ªôt|hai|ba|b·ªën|nƒÉm|s√°u|b·∫£y|t√°m|ch√≠n|m∆∞·ªùi)\s*(x·ªã|c·ªß|k|ngh√¨n|ng√†n|tri·ªáu|t·ª∑|ƒë·ªìng|vnd)?(?:\s|$)'

        # C·∫≠p nh·∫≠t danh s√°ch t·ª´ kh√≥a thu nh·∫≠p
        income_keywords = [
            'nh·∫≠n', 'l∆∞∆°ng', 'th∆∞·ªüng', 'ƒë∆∞·ª£c', 'cho', 't·∫∑ng', 'tr·ª£ c·∫•p', 'ho√†n ti·ªÅn',
            'l√£i', 'ti·ªÅn l√£i', 'c·ªï t·ª©c', 'ti·ªÅn v·ªÅ', 'chuy·ªÉn kho·∫£n', 'chuy·ªÉn ti·ªÅn',
            'thu nh·∫≠p', 'thu', 'ki·∫øm', 'b√°n', 'b√°n ƒë∆∞·ª£c'
        ]

        for transaction in transactions:
            transaction = transaction.strip()
            if not transaction:
                continue

            # T√¨m s·ªë ti·ªÅn trong giao d·ªãch
            match = re.search(amount_pattern, transaction)
            if match:
                description, number, unit = match.groups()
                amount_str = f"{number} {unit if unit else ''}"

                # X·ª≠ l√Ω s·ªë ti·ªÅn
                amount = self.amount_parser.normalize_amount(amount_str)

                # X√°c ƒë·ªãnh lo·∫°i giao d·ªãch TR∆Ø·ªöC KHI l√†m b·∫•t c·ª© ƒëi·ªÅu g√¨ kh√°c
                transaction_type = "EXPENSE"  # M·∫∑c ƒë·ªãnh l√† chi ti√™u
                description_lower = description.lower()

                # Ki·ªÉm tra t·ª´ kh√≥a thu nh·∫≠p
                if any(keyword in description_lower for keyword in income_keywords):
                    transaction_type = "INCOMING"

                # T√¨m category v√† c·ª•m t·ª´ c√≥ √Ω nghƒ©a
                best_category = self.categorize_transaction(description)
                meaningful_phrase = self.extract_meaningful_phrase(
                    description.lower())

                # S·ª≠ d·ª•ng c·ª•m t·ª´ c√≥ √Ω nghƒ©a l√†m m√¥ t·∫£
                description = meaningful_phrase if meaningful_phrase else description.strip()

                # X√≥a c√°c t·ª´ kh√≥a v·ªÅ ti·ªÅn
                money_keywords = ['ƒë·ªìng', 'vnd', 'ngh√¨n', 'ng√†n',
                                  'k', 'h·∫øt', 'm·∫•t', 't·ªën', 'chi', 'x·ªã', 'c·ªß']
                for keyword in money_keywords:
                    description = re.sub(
                        r'\s*\b' + keyword + r'\b\s*', ' ', description)

                # Th√™m v√†o k·∫øt qu·∫£ n·∫øu h·ª£p l·ªá
                if description and amount > 0:
                    result = {
                        "item": description.strip(),
                        "amount": int(amount),
                        "category": best_category,
                        "type": transaction_type,  # ƒê·∫£m b·∫£o type ƒë∆∞·ª£c g√°n ƒë√∫ng
                        "wallet": wallet
                    }
                    results.append(result)

        return results

    def categorize_transaction(self, description: str) -> dict:
        """Ph√¢n lo·∫°i giao d·ªãch d·ª±a tr√™n m√¥ t·∫£"""
        description = description.lower()

        # T√¨m category ph√π h·ª£p nh·∫•t d·ª±a tr√™n t·ª´ kh√≥a
        best_match = None
        max_matches = 0

        for category_id, category in self.category_keywords.items():
            matches = 0
            for keyword in category["keywords"]:
                if keyword in description:
                    matches += 1

            if matches > max_matches:
                max_matches = matches
                best_match = {
                    "id": category_id,
                    "name": category["name"],
                    "type": category["type"]
                }

        # N·∫øu kh√¥ng t√¨m th·∫•y category ph√π h·ª£p, tr·∫£ v·ªÅ m·∫∑c ƒë·ªãnh
        if not best_match:
            return {
                "id": "4287f00a-9f2c-4ec9-bfac-9310a5430b13",  # ID c·ªßa category ƒÇn u·ªëng
                "name": "üç≤ ƒÇn u·ªëng",
                "type": "EXPENSE"
            }

        return best_match

    def extract_meaningful_phrase(self, text: str) -> str:
        """Tr√≠ch xu·∫•t c·ª•m t·ª´ c√≥ √Ω nghƒ©a t vƒÉn b·∫£n theo c·∫•u tr√∫c ng·ªØ ph√°p"""
        text = text.lower()

        # ƒê·ªãnh nghƒ©a c√°c ƒë·ªông t·ª´ ch√≠nh v√† danh t·ª´ ƒëi k√®m
        verb_noun_pairs = {
            "ƒÉn": ["s√°ng", "tr∆∞a", "t·ªëi", "v·∫∑t", "c∆°m", "ph·ªü", "b√∫n", "ch√°o", "ƒë·ªì", "b√°nh"],
            "u·ªëng": ["n∆∞·ªõc", "cafe", "sinh t·ªë", "tr√† s·ªØa", "bia", "r∆∞·ª£u"],
            "mua": ["ƒë·ªì", "s·ªØa", "b√°nh", "qu·∫ßn √°o", "gi√†y d√©p", "thu·ªëc"],
            "xem": ["phim", "k·ªãch", "ca nh·∫°c", "b√≥ng ƒë√°"],
            "ƒë·ªï": ["xƒÉng", "d·∫ßu"],
            "n·∫°p": ["ti·ªÅn", "th·∫ª", "ƒëi·ªán tho·∫°i"],
            "thu√™": ["nh√†", "tr·ªç", "ph√≤ng"],
            "ƒë√≥ng": ["ti·ªÅn", "h·ªçc ph√≠", "ƒëi·ªán", "n∆∞·ªõc"],
            "tr·∫£": ["ti·ªÅn", "n·ª£", "g√≥p"],
            "g·ª≠i": ["xe"],
            "ch∆°i": ["game", "ƒëi·ªán t·ª≠", "bowling", "bi-a", "bida", "karaoke", "b√≥ng ƒë√°", "b√≥ng r·ªï", "c·∫ßu l√¥ng"],
            "ƒëi": ["ch∆°i", "cafe", "xem phim", "karaoke", "du l·ªãch", "d·∫°o", "ƒÉn"],
            "ƒë√°nh": ["game", "bida", "bi-a", "bowling", "c·∫ßu l√¥ng", "b√≥ng ƒë√°"],
            "h√°t": ["karaoke"],
            # Th√™m ƒë·ªông t·ª´ ƒë∆°n kh√¥ng c·∫ßn danh t·ª´ ƒëi k√®m
            "_single_verbs": ["ch∆°i", "h√°t", "nh·∫£y"]
        }

        # T√¨m c·ª•m ƒë·ªông t·ª´ + danh t·ª´
        for verb, nouns in verb_noun_pairs.items():
            if verb in text:
                # B·ªè qua key ƒë·∫∑c bi·ªát
                if verb == "_single_verbs":
                    continue

                # L·∫•y ph·∫ßn text sau ƒë·ªông t·ª´
                after_verb = text[text.index(verb) + len(verb):].strip()

                # T√¨m danh t·ª´ ph√π h·ª£p nh·∫•t
                for noun in sorted(nouns, key=len, reverse=True):
                    if noun in after_verb:
                        return f"{verb} {noun}".strip()

                # N·∫øu l√† ƒë·ªông t·ª´ ƒë∆°n c√≥ th·ªÉ ƒë·ª©ng m·ªôt m√¨nh
                if verb in verb_noun_pairs["_single_verbs"]:
                    return verb

                # N·∫øu kh√¥ng t√¨m th·∫•y danh t·ª´ ƒë·ªãnh nghƒ©a s·∫µn,
                # l·∫•y t·ª´ ti·∫øp theo sau ƒë·ªông t·ª´ (t·ªëi ƒëa 2 t·ª´)
                next_words = ' '.join(after_verb.split()[:2])
                if next_words:
                    return f"{verb} {next_words}".strip()

                return verb

        # N·∫øu kh√¥ng t√¨m th·∫•y c·∫•u tr√∫c ƒë·ªông t·ª´ + danh t·ª´,
        # t√¨m t·ª´ kh√≥a trong danh s√°ch category
        for category in self.category_keywords.values():
            for keyword in sorted(category["keywords"], key=len, reverse=True):
                if keyword in text:
                    # T√¨m th√™m t·ª´ xung quanh ƒë·ªÉ l√†m r√µ nghƒ©a
                    idx = text.index(keyword)
                    words = text.split()
                    keyword_idx = -1

                    # T√¨m v·ªã tr√≠ c·ªßa t·ª´ kh√≥a trong list t·ª´
                    for i, word in enumerate(words):
                        if keyword in word:
                            keyword_idx = i
                            break

                    if keyword_idx >= 0:
                        # L·∫•y t·ªëi ƒëa 2 t·ª´ tr∆∞·ªõc v√† sau t·ª´ kh√≥a
                        start = max(0, keyword_idx - 1)
                        end = min(len(words), keyword_idx + 2)
                        return ' '.join(words[start:end])

                    return keyword

        return text.strip()
